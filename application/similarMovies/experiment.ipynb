{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Johnson\n",
      "[nltk_data]     Lui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Johnson\n",
      "[nltk_data]     Lui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Johnson\n",
      "[nltk_data]     Lui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import re\n",
    "sys.path.append(\"..\")\n",
    "from dataAggregation.json_processor import json_unzip\n",
    "from utils.preprocess import preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Compressed Dataset\n",
    "zipped_dataset = pickle.load(open(\"../../data/movies_review_json_zip.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the Dataset\n",
    "movie_data = json_unzip(zipped_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "topK_movie = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Movie ID\n",
    "movie_id_list = list(movie_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Vocabulary\n",
    "preprocessed_corpus = []\n",
    "for m_id in movie_id_list:\n",
    "    # Put Movie Title and Plot as the summary of the movie\n",
    "    movie_name = movie_data[m_id][\"localized_title\"]\n",
    "    summary = movie_data[m_id][\"summary\"].split(\"\\nPlot: \")\n",
    "    summary = summary[1] if len(summary) > 1 else \"\"\n",
    "        \n",
    "    preprocessed_corpus.append(\n",
    "        preprocess(movie_name, is_sw_remove=False) + preprocess(summary)\n",
    "    )\n",
    "\n",
    "preprocessed_corpus_join = []\n",
    "for pc in preprocessed_corpus:\n",
    "    preprocessed_corpus_join.append(' '.join(pc))\n",
    "\n",
    "\n",
    "preprocessed_corpus_nosw = []\n",
    "for m_id in movie_id_list:\n",
    "    # Put Movie Title and Plot as the summary of the movie\n",
    "    movie_name = movie_data[m_id][\"localized_title\"]\n",
    "    summary = movie_data[m_id][\"summary\"].split(\"\\nPlot: \")\n",
    "    summary = summary[1] if len(summary) > 1 else \"\"\n",
    "\n",
    "    preprocessed_corpus_nosw.append(\n",
    "        preprocess(movie_name, is_sw_remove=False) + preprocess(summary, is_sw_remove=False)\n",
    "    )\n",
    "\n",
    "preprocessed_corpus_join_nosw = []\n",
    "for pc in preprocessed_corpus_nosw:\n",
    "    preprocessed_corpus_join_nosw.append(' '.join(pc))\n",
    "\n",
    "\n",
    "raw_corpus = []\n",
    "for m_id in movie_id_list:\n",
    "    # Put Movie Title and Plot as the summary of the movie\n",
    "    movie_name = movie_data[m_id][\"localized_title\"]\n",
    "    summary = movie_data[m_id][\"summary\"].split(\"\\nPlot: \")\n",
    "    summary = summary[1] if len(summary) > 1 else \"\"\n",
    "\n",
    "    raw_corpus.append(\n",
    "        re.sub(r\"[^a-zA-Z0-9 ]\", \"\", movie_name).lower().split(\" \") +\n",
    "        re.sub(r\"[^a-zA-Z0-9 ]\", \"\", summary).lower().split(\" \")\n",
    "    )\n",
    "\n",
    "raw_corpus_join = []\n",
    "for pc in raw_corpus:\n",
    "    raw_corpus_join.append(' '.join(pc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluator import MetricsEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Metrics Evaluator\n",
    "evaluator = MetricsEvaluator(movie_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from similarity.random import RandomCalculator\n",
    "\n",
    "random_calculator = RandomCalculator(movie_data, topK_movie)\n",
    "similar_movies_result_random = random_calculator.generateSimilarMovies()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random walk\n",
      "Average DCG: 1.6449281091741155\n",
      "Std DCG: 1.0411774399440266\n"
     ]
    }
   ],
   "source": [
    "dcg_result = evaluator.evaluate(similar_movies_result_random)\n",
    "print(\"Random walk\")\n",
    "print(f\"Average DCG: {np.mean(dcg_result)}\")\n",
    "print(f\"Std DCG: {np.std(dcg_result)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from similarity.jaccard import JaccardCalculator\n",
    "\n",
    "# Create Jaccard Similarity Calculator\n",
    "jaccard_calculator = JaccardCalculator(preprocessed_corpus)\n",
    "# Build Simiarity Matrix\n",
    "jaccard_calculator.buildSimilarityMatrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Similar Movie Result\n",
    "similar_movies_result_jaccard = {}\n",
    "for i in range(len(preprocessed_corpus)):\n",
    "    similar_movies = (-jaccard_calculator.sim_matrix[i]).argsort()[:topK_movie + 1]\n",
    "    similar_movies = [movie_id_list[j] for j in similar_movies if j != i][:topK_movie]\n",
    "\n",
    "    assert movie_id_list[i] not in similar_movies, \"Movie ID in Similar Movies List\"\n",
    "\n",
    "    similar_movies_result_jaccard[movie_id_list[i]] = similar_movies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random walk\n",
      "Average DCG: 2.338252519004315\n",
      "Std DCG: 1.0358377806742958\n"
     ]
    }
   ],
   "source": [
    "dcg_result = evaluator.evaluate(similar_movies_result_jaccard)\n",
    "print(\"Jaccard Similarity\")\n",
    "print(f\"Average DCG: {np.mean(dcg_result)}\")\n",
    "print(f\"Std DCG: {np.std(dcg_result)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF-IDF Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from similarity.tfidf import TFIDFCalculator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_calculator = TFIDFCalculator(preprocessed_corpus_join)\n",
    "tfidf_calculator.buildSimilarityMatrix()\n",
    "\n",
    "# Calculate Similar Movie Result\n",
    "similar_movies_result_tfidf = {}\n",
    "for i in range(len(preprocessed_corpus_join)):\n",
    "    similar_movies = (\n",
    "        -tfidf_calculator.sim_matrix[i]\n",
    "    ).argsort()[:topK_movie + 1]\n",
    "    similar_movies = [\n",
    "        movie_id_list[j] for j in similar_movies if j != i\n",
    "    ][:topK_movie]\n",
    "\n",
    "    assert movie_id_list[i] not in similar_movies, \"Movie ID in Similar Movies List\"\n",
    "\n",
    "    similar_movies_result_tfidf[movie_id_list[i]] = similar_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Similarity (With Stopword Removal)\n",
      "Average DCG: 2.334625692622194\n",
      "Std DCG: 1.0358093978760579\n"
     ]
    }
   ],
   "source": [
    "dcg_result = evaluator.evaluate(similar_movies_result_tfidf)\n",
    "print(\"TFIDF Similarity (With Stopword Removal)\")\n",
    "print(f\"Average DCG: {np.mean(dcg_result)}\")\n",
    "print(f\"Std DCG: {np.std(dcg_result)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_calculator = TFIDFCalculator(preprocessed_corpus_join_nosw)\n",
    "tfidf_calculator.buildSimilarityMatrix()\n",
    "\n",
    "# Calculate Similar Movie Result\n",
    "similar_movies_result_tfidf = {}\n",
    "for i in range(len(preprocessed_corpus_join_nosw)):\n",
    "    similar_movies = (\n",
    "        -tfidf_calculator.sim_matrix[i]\n",
    "    ).argsort()[:topK_movie + 1]\n",
    "    similar_movies = [\n",
    "        movie_id_list[j] for j in similar_movies if j != i\n",
    "    ][:topK_movie]\n",
    "\n",
    "    assert movie_id_list[i] not in similar_movies, \"Movie ID in Similar Movies List\"\n",
    "\n",
    "    similar_movies_result_tfidf[movie_id_list[i]] = similar_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Similarity (Without Stopword Removal)\n",
      "Average DCG: 2.3517530416134167\n",
      "Std DCG: 1.0351286699006752\n"
     ]
    }
   ],
   "source": [
    "dcg_result = evaluator.evaluate(similar_movies_result_tfidf)\n",
    "print(\"TFIDF Similarity (Without Stopword Removal)\")\n",
    "print(f\"Average DCG: {np.mean(dcg_result)}\")\n",
    "print(f\"Std DCG: {np.std(dcg_result)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-Trained Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from similarity.gensim import GensimCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_calculator = GensimCalculator(raw_corpus, \"word2vec-google-news-300\")\n",
    "gensim_calculator.buildSimilarityMatrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Similar Movie Result\n",
    "similar_movies_result_gensim = {}\n",
    "for i in range(len(preprocessed_corpus_join_nosw)):\n",
    "    similar_movies = (\n",
    "        -gensim_calculator.sim_matrix[i]\n",
    "    ).argsort()[:topK_movie + 1]\n",
    "    similar_movies = [\n",
    "        movie_id_list[j] for j in similar_movies if j != i\n",
    "    ][:topK_movie]\n",
    "\n",
    "    assert movie_id_list[i] not in similar_movies, \"Movie ID in Similar Movies List\"\n",
    "\n",
    "    similar_movies_result_gensim[movie_id_list[i]] = similar_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenSim Similarity (word2vec-google-news-300)\n",
      "Average DCG: 2.4507202544319235\n",
      "Std DCG: 1.043982208164629\n"
     ]
    }
   ],
   "source": [
    "dcg_result = evaluator.evaluate(similar_movies_result_gensim)\n",
    "print(\"GenSim Similarity (word2vec-google-news-300)\")\n",
    "print(f\"Average DCG: {np.mean(dcg_result)}\")\n",
    "print(f\"Std DCG: {np.std(dcg_result)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
     ]
    }
   ],
   "source": [
    "gensim_calculator = GensimCalculator(raw_corpus, \"fasttext-wiki-news-subwords-300\")\n",
    "gensim_calculator.buildSimilarityMatrix()\n",
    "\n",
    "# Calculate Similar Movie Result\n",
    "similar_movies_result_gensim = {}\n",
    "for i in range(len(preprocessed_corpus_join_nosw)):\n",
    "    similar_movies = (\n",
    "        -gensim_calculator.sim_matrix[i]\n",
    "    ).argsort()[:topK_movie + 1]\n",
    "    similar_movies = [\n",
    "        movie_id_list[j] for j in similar_movies if j != i\n",
    "    ][:topK_movie]\n",
    "\n",
    "    assert movie_id_list[i] not in similar_movies, \"Movie ID in Similar Movies List\"\n",
    "\n",
    "    similar_movies_result_gensim[movie_id_list[i]] = similar_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenSim Similarity (fasttext-wiki-news-subwords-300)\n",
      "Average DCG: 2.196003871343459\n",
      "Std DCG: 1.0621610054556159\n"
     ]
    }
   ],
   "source": [
    "dcg_result = evaluator.evaluate(similar_movies_result_gensim)\n",
    "print(\"GenSim Similarity (fasttext-wiki-news-subwords-300)\")\n",
    "print(f\"Average DCG: {np.mean(dcg_result)}\")\n",
    "print(f\"Std DCG: {np.std(dcg_result)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_calculator = GensimCalculator(raw_corpus, \"glove-twitter-200\")\n",
    "gensim_calculator.buildSimilarityMatrix()\n",
    "\n",
    "# Calculate Similar Movie Result\n",
    "similar_movies_result_gensim = {}\n",
    "for i in range(len(preprocessed_corpus_join_nosw)):\n",
    "    similar_movies = (\n",
    "        -gensim_calculator.sim_matrix[i]\n",
    "    ).argsort()[:topK_movie + 1]\n",
    "    similar_movies = [\n",
    "        movie_id_list[j] for j in similar_movies if j != i\n",
    "    ][:topK_movie]\n",
    "\n",
    "    assert movie_id_list[i] not in similar_movies, \"Movie ID in Similar Movies List\"\n",
    "\n",
    "    similar_movies_result_gensim[movie_id_list[i]] = similar_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenSim Similarity (glove-twitter-200)\n",
      "Average DCG: 2.257351379313323\n",
      "Std DCG: 1.062587634837154\n"
     ]
    }
   ],
   "source": [
    "dcg_result = evaluator.evaluate(similar_movies_result_gensim)\n",
    "print(\"GenSim Similarity (glove-twitter-200)\")\n",
    "print(f\"Average DCG: {np.mean(dcg_result)}\")\n",
    "print(f\"Std DCG: {np.std(dcg_result)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8c0bb826b0a6d814e23aa5e5c30ff79c87019379740d931cfcd76fca69e3581"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
